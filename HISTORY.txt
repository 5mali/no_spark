      eno_sarsa
           |
      -----|-----
      |         |
eno_dqn         eno_dsn
      |         |
      -----|-----
           |
       dsn_proto
           |
          /
         |
      dsn_v0
         |
        /
       |
    dsn_exp
       |
      /    
     |
 dsn_exp_t1
     |
    /
   | 
 dsn_v
   |
  /
 |
dsnv3
 |
 |
dsn_prime: 
 |---------> A to L: Using reward function that is based on BOPT  (REWARD FUNCTION 0)
 |
 |---------> M to Y: Using reward function that is based on BMEAN (REWARD FUNCTION 1)
 |
 |---------> Did not realize that there was no activations between the fully connected layers. !!!BLUNDER!!!
 |---------> Only RELU before the output layer
 |
 |---------> Weight Regularization (L2) loss introduced from D.
 |
 |
eno_dsn_A: 
 |
 |---------> ORIGIN: dsn_prime(U-seed0) -> 0U: INPUT->FC1->FC2->RELU->OUT
 |
 |---------> A: Multiplicative Rewards
 |           |
 |           |----> A2: Introduced bug in defining ENP = binit - sum(atrack)*DMIN              !!!BLUNDER!!!
 |
 |---------> B: Experimented with effects of weight initialization
 |
 |---------> C: Added activation functions between fully connected layers
 |           |
 |           |-----> C,D and E models experimented with RELU, LeRELU, TANH and SIGMOID activations
 |           |-----> Weight initialization using Kaiming and Xavier schemes were also introduced
 |           |-----> Huber loss was also investigated
 |           |
 |           |-----> 0CxA: Disruptive Training (Sawtooth EPSILON) introduced
 |
 |
dsn_eno
 |
 |---------> ORIGIN: 0C3A -> 00: INPUT->FC1->RELU->FC2->RELU->FC3->RELU->OUT
 |
 |---------> Increasing WIDTH and DEPTH to 50x3
 |
 |---------> C: RELU and SIGMOID Hybrid
 |           |
 |           |---> Re-experimentations with all hyper-parameters like width, target update etc etc.
 |
 |---------> F3: Using a more systematic reward function (REWARD FUNCTION 2)
 |
 |
all_spark :MAJOR BLUNDER IN DEFINING ENP for Reward Function 1
 |
 |
no_spark
