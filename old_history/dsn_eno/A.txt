**************************************************************
A
**************************************************************

                       
HYPOTHESIS:

- Increase WIDTH/DEPTH so that network learns better during disruption
This is so that catastrophic results don't appear.

- Disruptive training with sawtooth EPSILON ranging from 0.5 to 0.95 to make model more robust


MODEL:
A : INPUT->FC1->RELU->FC2->RELU->FC3->RELU->OUT
LOSS : MSE

LEARNING:   INIT_WEIGHT     = FC1 : KAIMING
                              FC2 : KAIMING
                              FC3 : KAIMING
                              OUT : XAVIER
            WIDTH           = 50
            DEPTH           = 3
            WEIGHT_DECAY    = 1E-3
            LR              = 1E-4
            UPDATE_FREQ     = 18 MONTHS
            MEMORY          = 24 MONTHS
            ITERATION       = 50
            BATCH_SIZE      = 32
            EPSILON         = SAWTOOTH (0.5-0.95)              
            GAMMA           = 0.9                
            LAMBDA          = 0.9
            
TRAINING:   TOKYO[2000-2009]
            BATTERY_RESET    = 0 %
            REWARD_FUNC      = TYPE2
                               violation_penalty = 3
                               battery full = -2
                               battery dead = -4
                               R = r1*(2**r2) - violation_penalty
            REWARD_BROADCAST = TRUE
            
            LAST TRAINING ITERATIONS = 10 [TOKYO, 2000-2009]
            EPSILON                  = 0.95
            LR                       = 1E-4
            
TESTING:    TOKYO[2000-2018]
            GREEDY POLICY
   
*********
RESULTS:
*********
SEED 0
2000 		 1.47 		 0
2001 		 1.5 		 0
2002 		 1.4 		 0
2003 		 1.43 		 2
2004 		 1.45 		 1
2005 		 1.55 		 0
2006 		 1.45 		 0
2007 		 1.45 		 2
2008 		 1.52 		 0
2009 		 1.46 		 0
2010 		 1.46 		 0
2011 		 1.52 		 0
2012 		 1.47 		 0
2013 		 1.47 		 0
2014 		 1.39 		 1
2015 		 1.41 		 0
2016 		 1.43 		 2
2017 		 1.47 		 0
2018 		 1.42 		 1

SEED 1
2000 		 1.43 		 0
2001 		 1.48 		 0
2002 		 1.31 		 2
2003 		 1.4 		 2
2004 		 1.44 		 0
2005 		 1.49 		 0
2006 		 1.42 		 0
2007 		 1.43 		 0
2008 		 1.44 		 0
2009 		 1.43 		 0
2010 		 1.44 		 0
2011 		 1.49 		 0
2012 		 1.41 		 0
2013 		 1.45 		 0
2014 		 1.38 		 0
2015 		 1.39 		 0
2016 		 1.43 		 0
2017 		 1.46 		 1
2018 		 1.4 		 0

SEED 2
2000 		 1.38 		 2
2001 		 1.48 		 0
2002 		 1.3 		 3
2003 		 1.36 		 4
2004 		 1.43 		 1
2005 		 1.52 		 0
2006 		 1.42 		 0
2007 		 1.44 		 1
2008 		 1.45 		 0
2009 		 1.43 		 0
2010 		 1.44 		 2
2011 		 1.51 		 0
2012 		 1.46 		 0
2013 		 1.46 		 0
2014 		 1.34 		 3
2015 		 1.38 		 0
2016 		 1.42 		 1
2017 		 1.49 		 0
2018 		 1.39 		 3

SEED 3
2000 		 1.36 		 0
2001 		 1.42 		 0
2002 		 1.27 		 2
2003 		 1.32 		 4
2004 		 1.32 		 3
2005 		 1.45 		 0
2006 		 1.35 		 0
2007 		 1.35 		 2
2008 		 1.4 		 1
2009 		 1.37 		 0
2010 		 1.35 		 2
2011 		 1.4 		 4
2012 		 1.35 		 0
2013 		 1.35 		 3
2014 		 1.23 		 6
2015 		 1.28 		 2
2016 		 1.34 		 3
2017 		 1.38 		 3
2018 		 1.29 		 4

SEED 4
2000 		 1.32 		 3
2001 		 1.42 		 0
2002 		 1.26 		 2
2003 		 1.26 		 5
2004 		 1.39 		 0
2005 		 1.46 		 2
2006 		 1.29 		 0
2007 		 1.39 		 0
2008 		 1.41 		 1
2009 		 1.34 		 2
2010 		 1.37 		 1
2011 		 1.48 		 1
2012 		 1.41 		 0
2013 		 1.46 		 0
2014 		 1.31 		 3
2015 		 1.33 		 0
2016 		 1.4 		 0
2017 		 1.43 		 2
2018 		 1.4 		 0

SEED 5
2000 		 1.38 		 0
2001 		 1.43 		 0
2002 		 1.33 		 0
2003 		 1.35 		 0
2004 		 1.36 		 0
2005 		 1.45 		 0
2006 		 1.36 		 0
2007 		 1.4 		 0
2008 		 1.42 		 0
2009 		 1.37 		 0
2010 		 1.39 		 0
2011 		 1.46 		 0
2012 		 1.37 		 0
2013 		 1.41 		 0
2014 		 1.33 		 0
2015 		 1.34 		 0
2016 		 1.39 		 0
2017 		 1.44 		 0
2018 		 1.37 		 0

SEED 6
2000 		 1.45 		 0
2001 		 1.49 		 0
2002 		 1.4 		 0
2003 		 1.43 		 1
2004 		 1.46 		 0
2005 		 1.52 		 0
2006 		 1.45 		 0
2007 		 1.47 		 0
2008 		 1.49 		 0
2009 		 1.46 		 0
2010 		 1.46 		 0
2011 		 1.52 		 0
2012 		 1.46 		 0
2013 		 1.48 		 0
2014 		 1.41 		 0
2015 		 1.41 		 0
2016 		 1.45 		 0
2017 		 1.5 		 0
2018 		 1.43 		 0


***************************
DISCUSSION AND CONCLUSIONS
***************************
Very good results with stable/robust outputs